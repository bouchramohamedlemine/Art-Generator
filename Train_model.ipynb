{"cells":[{"cell_type":"code","source":["# ***************** Import the necessary libraries *****************\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch import nn\n","import torch.optim as optim\n","from torchvision.utils import save_image\n","from torch.utils.data import ConcatDataset\n","from torchvision import transforms\n","\n","from PIL import Image\n","import pandas as pd\n","import numpy as np\n","import sys\n","import os\n","import random\n","import matplotlib.pyplot as plt\n","\n","# Mount the google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","sys.path.insert(0, 'drive/MyDrive/CI642_Coursework')\n","\n","from Generator_class import Generator\n","from Discriminator_class import Discriminator\n","from CustomDataset_class import CustomDataset\n","from Utils import plot_images, initialise_weights, test_implementation, calculate_CID_indices"],"metadata":{"id":"FlJ2FEQlogGc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ohErb1G-Qk7z"},"outputs":[],"source":["# ***************** Initialise the hyperparameters *****************\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","learning_rate = 1e-3\n","batch_size = 128\n","num_classes = 5\n","img_size = 64\n","img_channels = 3\n","z_dim = 100\n","epochs = 50\n","discriminator_num_filters = 128\n","generator_num_filters = 128\n","\n","data_folder = \"drive/MyDrive/CI642_Coursework/Dataset\""]},{"cell_type":"code","source":["# ***************** Pre-processing and loading the dataset *****************\n","\n","# Resize the images, convert them to tensors, and normalise the image channels to have 0.5 mean and standard deviation.\n","transform = transforms.Compose(\n","    [\n","      transforms.Resize((img_size, img_size)),\n","      transforms.ToTensor(),\n","      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","    ])\n","\n","\n","training_data = []\n","\n","classes = {}\n","\n","# Disable the PIL image limit\n","Image.MAX_IMAGE_PIXELS = None\n","\n","# Every folder in data_folder contains images of a specific class and is named with the format ClassIndex_ClassName\n","for img_class in os.listdir(data_folder):\n","\n","  classes[int(img_class.split(\"_\")[0])] = img_class.split(\"_\")[1]\n","\n","  # Get full paths of all images in this folder\n","  imgs_paths = [os.path.join(data_folder, img_class, img) for img in os.listdir(os.path.join(data_folder, img_class))]\n","\n","  for img in imgs_paths:\n","    image = Image.open(img)\n","    # Delete images that do not have exactly 3 channels\n","    if len(list(np.array(image).shape)) != 3:\n","      print(img, np.array(image).shape)\n","      os.remove(img)\n","\n","  print(f\"************ There are {len(os.listdir(os.path.join(data_folder, img_class)))} {img_class.split('_')[1]} images\")\n","\n","  # Put these images into a CustomDataset object\n","  dataset = CustomDataset(imgs_paths, int(img_class.split(\"_\")[0]), img_class.split(\"_\")[1], transform=transform)\n","\n","  training_data.append(dataset)\n","\n","# Create a training dataloader to iterate over the training data\n","train_dataloader = torch.utils.data.DataLoader(ConcatDataset(training_data), batch_size=batch_size, shuffle=True)"],"metadata":{"id":"TrhicfwDoZfZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ***************** Show 10 sample images from the training dataset *****************\n","\n","dataiter = iter(train_dataloader)\n","images, label_indices, label_names = next(dataiter)\n","plot_images(images[:10], label_names[:10])"],"metadata":{"id":"eaPufzOnBSRN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ***************** Test the architecture implementation before starting the training *****************\n","\n","test_implementation(num_samples = 5, img_channels = 3, img_size = img_size, num_classes = 5, noise_dim = z_dim, labels = torch.LongTensor(np.arange(5)), disc_num_feature_maps = discriminator_num_filters, gen_num_feature_maps = generator_num_filters)"],"metadata":{"id":"So1WsllkBNXc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ***************** Initialise the generator and discriminator objects, and their optimisers *****************\n","\n","generator = Generator(z_dim, img_channels, generator_num_filters, num_classes).to(device)\n","initialise_weights(generator)\n","print(generator)\n","\n","discriminator = Discriminator(img_channels, discriminator_num_filters, num_classes, img_size).to(device)\n","initialise_weights(discriminator)\n","print(discriminator)\n","\n","generator_optimiser = optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n","discriminator_optimiser = optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n","\n","# The training loss function (Binary Cross Entropy)\n","criterion = nn.BCELoss()"],"metadata":{"id":"Lh_W-oc5BJ3z"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ***************** Train the conditional DCGAN *****************\n","\n","# Put the generator and discriminator in training modes\n","generator.train()\n","discriminator.train()\n","\n","generator_losses = []\n","discriminator_losses = []\n","\n","\n","for epoch in range(epochs):\n","\n","  total_disc_loss = 0\n","  total_gen_loss = 0\n","\n","  for batch_index, (real_imgs, label_indices, label_names) in enumerate(train_dataloader):\n","\n","    real_imgs = real_imgs.to(device)\n","    label_indices = label_indices.to(device)\n","\n","    # Generate a batch of images from the random noise\n","    noise = torch.randn(len(real_imgs), z_dim, 1, 1).to(device)\n","    fake_imgs = generator(noise, label_indices)\n","\n","    # ******* Train the discriminator\n","\n","    # Make the discriminator trainable\n","    for param in discriminator.parameters():\n","      param.requires_grad = True\n","\n","    discriminator_optimiser.zero_grad()\n","\n","    # Set the ground truth for the real images to 1\n","    # Calculate the loss of the discriminator on real images\n","    real_imgs_output = discriminator(real_imgs, label_indices).reshape(-1)\n","    real_imgs_loss = criterion(real_imgs_output, torch.full_like(real_imgs_output, 0.9)) # Apply label smoothing\n","\n","    # Set the ground truth for the fake images to 0\n","    # Calculate the loss of the discriminator on fake images\n","    fake_imgs_output = discriminator(fake_imgs, label_indices).reshape(-1)\n","    fake_imgs_loss = criterion(fake_imgs_output, torch.zeros_like(fake_imgs_output))\n","\n","    # Measure the total discriminator loss\n","    discriminator_loss = (real_imgs_loss + fake_imgs_loss) / 2\n","    total_disc_loss += discriminator_loss.item()\n","\n","    # Perform the backward propagation and update the model parameters\n","    discriminator_loss.backward(retain_graph=True)\n","    discriminator_optimiser.step()\n","\n","\n","    # ******* Train the generator\n","    generator_optimiser.zero_grad()\n","\n","    # Make the discriminator untrainable\n","    for param in discriminator.parameters():\n","      param.requires_grad = False\n","\n","    # Set the ground truth for the fake images to 1\n","    # Calculate the loss of the discriminator on fake images\n","    fake_imgs_output = discriminator(fake_imgs, label_indices).reshape(-1)\n","    generator_loss = criterion(fake_imgs_output, torch.full_like(fake_imgs_output, 0.9)) # Apply label smoothing\n","\n","    total_gen_loss += generator_loss.item()\n","\n","    # Perform backpropagation and update parameters according to the gradient from the discriminator\n","    generator_loss.backward(retain_graph=True)\n","    generator_optimiser.step()\n","\n","\n","  generator_losses.append(total_gen_loss)\n","  discriminator_losses.append(total_disc_loss)\n","\n","\n","  # After every 5 epochs, validate the generator.\n","  if epoch % 5 == 0:\n","    print(\n","        f\"\\n************************************************************************* \\\n","        \\nEpoch {epoch} | Discriminator Loss: {total_disc_loss:.4f}, generator loss: {total_gen_loss:.4f}\"\n","    )\n","\n","    with torch.no_grad():\n","      generator.eval()\n","\n","      # Create random noise\n","      noise = torch.randn(num_classes, z_dim, 1, 1).to(device)\n","      labels = torch.LongTensor(np.arange(num_classes)).to(device)\n","\n","      # Generate an image for each class\n","      generated_imgs = generator(noise, labels).squeeze(1).data.cpu()\n","\n","      # Show the generated images and their labels\n","      plot_images(generated_imgs, list(map(lambda x: classes[x], labels.cpu().numpy())))\n","\n","    # Put the generator back in the training mode\n","    generator.train()\n","\n","# ***************** Save the models *****************\n","torch.save(generator.state_dict(), f\"drive/MyDrive/CI642_Coursework/generator_model.pth\")\n","torch.save(discriminator.state_dict(), f\"drive/MyDrive/CI642_Coursework/discriminator_model.pth\")"],"metadata":{"id":"4iGgfmLoBAKb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RqhQV1LTajxc"},"outputs":[],"source":["# ***************** Plot the training loss curve *****************\n","\n","plt.figure(1)\n","plt.plot(range(len(discriminator_losses)), discriminator_losses, 'y', label=\"Discriminator loss\")\n","plt.plot(range(len(generator_losses)), generator_losses, 'c', label=\"Generator loss\")\n","plt.xlabel(\"Number of iteration\")\n","plt.ylabel(\"Loss\")\n","plt.title(\"Conditional DCGAN Training Loss Curve\")\n","plt.legend(loc=\"upper right\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3E3Vv_3TSyoY"},"outputs":[],"source":["# ***************** Save the models *****************\n","\n","torch.save(generator.state_dict(), \"drive/MyDrive/CI642_Coursework/generator_model.pth\")\n","torch.save(discriminator.state_dict(), \"drive/MyDrive/CI642_Coursework/discriminator_model.pth\")"]},{"cell_type":"code","source":["# ***************** Load the generator parameters and generate some images *****************\n","\n","generator = Generator(z_dim, img_channels, generator_num_filters, num_classes).to(device)\n","generator.load_state_dict(torch.load(\"drive/MyDrive/CI642_Coursework/generator_model.pth\"))\n","\n","# Create the noise vector and set the generated image labels to all class labels\n","noise = torch.randn(num_classes, z_dim, 1, 1).to(device)\n","labels = torch.LongTensor(np.arange(num_classes)).to(device)\n","\n","# Generate an image for each class\n","generated_imgs = generator(noise, labels)\n","generated_imgs = [(x.squeeze(1).data.cpu())  for x in generated_imgs]\n","\n","# Plot the generated images and their labels\n","plot_images(generated_imgs, list(map(lambda x: classes[x], labels.cpu().numpy())))"],"metadata":{"id":"6rKItCgdpD39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ***************** Evaluation *****************\n","\n","# Load the training images\n","training_images = {}\n","\n","for img_class in os.listdir(data_folder):\n","  label = int(img_class.split(\"_\")[0])\n","  # Get full paths of all images in this folder\n","  imgs_paths = [os.path.join(data_folder, img_class, img) for img in os.listdir(os.path.join(data_folder, img_class))]\n","\n","  training_images[label] = list(map(lambda img_path: np.array(Image.open(img_path).resize((64, 64))), imgs_paths))\n","\n","\n","# Calculate the CID indices\n","CID_indices = calculate_CID_indices(z_dim, generator, training_images, num_fake_imgs = 1000)\n","print(CID_indices)\n","\n","\n","# Plot the CID indices\n","x_axis = [i for i in CID_indices]\n","creativity_indices = [CID_indices[label][0] for label in CID_indices]\n","inheritance_indices = [CID_indices[label][1] for label in CID_indices]\n","diversity_indices = [CID_indices[label][2] for label in CID_indices]\n","\n","plt.figure(2)\n","plt.plot(x_axis, creativity_indices, 'y', label=\"Creativity Index\")\n","plt.plot(x_axis, inheritance_indices, 'c', label=\"Inhertance Index\")\n","plt.plot(x_axis, [(i)/(max(diversity_indices)) for i in diversity_indices], 'm', label=\"Diversity Index\")\n","plt.xticks(ticks = x_axis, labels = list(map(lambda i: classes[i], CID_indices)))\n","plt.xlabel(\"Image Class\")\n","plt.title(\"CID Indices Measured With 1000 Generated Images per Class\")\n","plt.legend(loc=\"center left\", bbox_to_anchor=(1, 0.5))\n","plt.show()"],"metadata":{"id":"52ayjcoapHin"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyMjaX+MzZicsSAv7dsztR7V"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}